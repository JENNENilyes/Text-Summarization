{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Projet Deep learning : Text_summarization"
      ],
      "metadata": {
        "id": "uo6qDep9fc9n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Data & Data undrestanding"
      ],
      "metadata": {
        "id": "2M35SYWjfmuz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IFwbwuApo7TO"
      },
      "outputs": [],
      "source": [
        "# # 1\n",
        "# !pip install tensorflow==2.0.0\n",
        "# # 2\n",
        "# !pip install keras==2.2.4\n",
        "# !pip install h5py==2.9.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3QnX8wWknwrE"
      },
      "outputs": [],
      "source": [
        "# 3\n",
        "!pip install tensorflow-gpu==1.15\n",
        "# import keras==2.2.4\n",
        "import numpy as np  \n",
        "import pandas as pd \n",
        "import re           \n",
        "import os\n",
        "from bs4 import BeautifulSoup \n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords   \n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "!pip install wget\n",
        "import wget\n",
        "import nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gqlRE8vpXa8",
        "outputId": "f2047e53-8b6d-4d40-f098-140acf193f5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1v8xFQeqSHy"
      },
      "outputs": [],
      "source": [
        "dataframe = pd.read_csv ('/content/drive/MyDrive/projet DL/20190928-reviews.csv')\n",
        "dataframe=pd.DataFrame(dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HIMGiPHqa7Q"
      },
      "outputs": [],
      "source": [
        "data=dataframe[['title','body']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUlL9kuqqpuE"
      },
      "outputs": [],
      "source": [
        "data=data.rename(columns={'body': 'Text', 'title': 'Summary'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4HYtCWX7qeLZ",
        "outputId": "87a321ac-f4e2-4e71-ac6f-04143beef49e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-56480bc0-f785-4354-af97-44d3a13e72e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>56669</th>\n",
              "      <td>I cannot talk about the functionality of the phone, because it was a gift. What I am happy about is the phone arrived earlier then expected. The phone looked brand new and it worked over in the Do...</td>\n",
              "      <td>Great value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60817</th>\n",
              "      <td>I love the phone but it does not let me download Instagram. It says this device it's not compatible with the app. Seller hasn't respond to my message.</td>\n",
              "      <td>Great pictures..</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57741</th>\n",
              "      <td>Does Not come in an apple box, (just charger and cable) but it looks and works like new. Good deal.</td>\n",
              "      <td>Looks like new, acts like new</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45035</th>\n",
              "      <td>Physically, phone was great, no visible scratches... However the battery life was poor ( couldn't last a day). Phone was not unlocked to my current network as promised..In spite of all the negativ...</td>\n",
              "      <td>phone was great, no visible scratches</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81781</th>\n",
              "      <td>Best budget phone for Google fans! This phone has undoubtedly the best value of money.</td>\n",
              "      <td>Best budget phone on the market!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56480bc0-f785-4354-af97-44d3a13e72e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-56480bc0-f785-4354-af97-44d3a13e72e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-56480bc0-f785-4354-af97-44d3a13e72e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                                                                                                                                                                          Text                                Summary\n",
              "56669  I cannot talk about the functionality of the phone, because it was a gift. What I am happy about is the phone arrived earlier then expected. The phone looked brand new and it worked over in the Do...                            Great value\n",
              "60817                                                   I love the phone but it does not let me download Instagram. It says this device it's not compatible with the app. Seller hasn't respond to my message.                       Great pictures..\n",
              "57741                                                                                                      Does Not come in an apple box, (just charger and cable) but it looks and works like new. Good deal.          Looks like new, acts like new\n",
              "45035  Physically, phone was great, no visible scratches... However the battery life was poor ( couldn't last a day). Phone was not unlocked to my current network as promised..In spite of all the negativ...  phone was great, no visible scratches\n",
              "81781                                                                                                                   Best budget phone for Google fans! This phone has undoubtedly the best value of money.       Best budget phone on the market!"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data[['Text','Summary']].sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qv471RvqzcX",
        "outputId": "2a125560-55fa-4f76-9763-8b682bf1cc14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(82815, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFrHI4CMqjoM"
      },
      "outputs": [],
      "source": [
        "data.drop_duplicates(subset=['Text'],inplace=True)  #dropping duplicates\n",
        "data.dropna(axis=0,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLDkgeQpq1rS",
        "outputId": "7210f5a9-49a3-4c01-8bd5-c0baf80054de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(72622, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "m3yQ-Po_hZck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.Remove emoji\n",
        "\n",
        "1.Convert everything to lowercase\n",
        "\n",
        "2.Remove HTML tags\n",
        "\n",
        "3.Contraction mapping\n",
        "\n",
        "4.Remove (‘s)\n",
        "\n",
        "5.Remove any text inside the parenthesis ( )\n",
        "\n",
        "6.Eliminate punctuations and special characters\n",
        "\n",
        "7.Remove stopwords\n",
        "\n",
        "8.Remove short words"
      ],
      "metadata": {
        "id": "H-rqhgRahqGH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7jmnZaGq5g7"
      },
      "outputs": [],
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "\n",
        "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tzi2zc43q6Ot",
        "outputId": "b51bf83f-0e43-4206-bc55-966102440534"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    I had the Samsung A600 for awhile which is absolute doo doo. You can read my review on it and detect my rage at the stupid thing. It finally died on me so I used this Nokia phone I bought in a gar...\n",
              "1    Due to a software issue between Nokia and Sprint this phone's text messaging capabilities don't work with Sprint's system and won't until a software patch comes out \"some time in the next few mont...\n",
              "2    This is a great, reliable phone. I also purchased this phone after my samsung A460 died. The menu is easily comprehendable and speed dialing is available for around 300 numbers. Voice dialing is a...\n",
              "3    I love the phone and all, because I really did need one, but I didn't expect the price of the bill when I received one. Also, I've had my phone for a little over two months now and still have yet ...\n",
              "4    The phone has been great for every purpose it offers, except the day i bought it-i couldnt get the case off. You can take the case off to put your own pictures in the jaket which is super cool, bu...\n",
              "5    Hello, I have this phone and used it until I decided to buy a flip phone. I have had NO problems with the battery or new cases--it has a new fish case on it now and it stays as well as the origina...\n",
              "6    Cool. Cheap. Color: 3 words that describe the Nokia 3588 perfectly. I mean, what more DO you want? This beauty's got classic, sleek looks that jerks you a little about a Nokia 3310's looks. The 35...\n",
              "7    The 3599i is overall a nice phone, except that Nokia made its universal headset jack incompatible with most 2.5mm universal headsets (even their own). A phone call to tech support was required to ...\n",
              "8    I've never owned a Nokia phone before, so this is a first for me. I really like the phone alot, the reception is great...even though the signal strength show's being low. The quality of the phone ...\n",
              "9    ok well im in school and i need the text messaging and ive had this phone for about a month and text messaging was supposed to start working 2weeks ago.A conflict of software type stuff and btween...\n",
              "Name: Text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "data['Text'][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMRPJ3IP1xWL",
        "outputId": "86ab8e78-e723-435a-f739-3a65ffe1eda8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emot\n",
            "  Downloading emot-3.1-py3-none-any.whl (61 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▎                          | 10 kB 20.7 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 20 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 30 kB 15.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 40 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 51 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61 kB 19 kB/s \n",
            "\u001b[?25hInstalling collected packages: emot\n",
            "Successfully installed emot-3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install emot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "D8hevcm0136Q",
        "outputId": "7798bdab-4526-4727-d1fa-6c9767025c04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hilarious ! The feeling of making a sale , The feeling of actually fulfilling orders '"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "def remove_emoji(string):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\" # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\" # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\" # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\" # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', string)\n",
        "\n",
        "remove_emoji(\"Hilarious 😂! The feeling of making a sale 😎, The feeling of actually fulfilling orders 😒\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjG-wdQg14Rj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udpwWuNMq84s",
        "outputId": "c202fc2c-443b-4b0c-c5db-b2c01a33cbab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english')) \n",
        "def text_cleaner(text):\n",
        "    newString = remove_emoji(text)\n",
        "    newString = text.lower()\n",
        "    newString = BeautifulSoup(newString, \"lxml\").text\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = re.sub('\"','', newString)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
        "    tokens = [w for w in newString.split() if not w in stop_words]\n",
        "    long_words=[]\n",
        "    for i in tokens:\n",
        "        if len(i)>=3:                  #removing short word\n",
        "            long_words.append(i)   \n",
        "    return (\" \".join(long_words)).strip()\n",
        "\n",
        "cleaned_text = []\n",
        "for t in data['Text']:\n",
        "    cleaned_text.append(text_cleaner(t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTGAgUYLq-f_",
        "outputId": "64af4cfd-8c4f-40cc-eb69-6993bc8ccc31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                     Def not best, but not worst\n",
              "1                     Text Messaging Doesn't Work\n",
              "2                                 Love This Phone\n",
              "3                         Love the Phone, BUT...!\n",
              "4    Great phone service and options, lousy case!\n",
              "5                             Worked great for me\n",
              "6             Wanna cool Nokia? You have it here!\n",
              "7            Problem with 3588i universal headset\n",
              "8                              cool phone!!!!!!!!\n",
              "9                         Pissed off-a little bit\n",
              "Name: Summary, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "data['Summary'][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJdkNoO5rCiZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "def summary_cleaner(text):\n",
        "    newString = remove_emoji(text)\n",
        "    newString = re.sub('\"','', text)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
        "    newString = newString.lower()\n",
        "    tokens=newString.split()\n",
        "    newString=''\n",
        "    for i in tokens:\n",
        "        if len(i)>1:                                 \n",
        "            newString=newString+i+' '  \n",
        "    return newString\n",
        "\n",
        "#Call the above function\n",
        "cleaned_summary = []\n",
        "for t in data['Summary']:\n",
        "    cleaned_summary.append(summary_cleaner(t))\n",
        "\n",
        "data['cleaned_text']=cleaned_text\n",
        "data['cleaned_summary']=cleaned_summary\n",
        "data['cleaned_summary'].replace('', np.nan, inplace=True)\n",
        "data.dropna(axis=0,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NijOhpjlrEJm"
      },
      "outputs": [],
      "source": [
        "data['cleaned_summary'] = data['cleaned_summary'].apply(lambda x : '_START_ '+ x + ' _END_')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kc1BkubrGHC",
        "outputId": "1149ce2c-423c-47e9-9ed7-f7f325f0b122"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: samsung awhile absolute doo doo read review detect rage stupid thing finally died used nokia phone bought garage sale wonder sold cheap bad hate menu takes forever get want scroll endlessly usually phones numbered categories simply press get want pain put silent vibrate class rings turn immediately fast way silence damn thing always remember put silent learned hard way true case mission get break nails process also damage case time try reason phone started giving problems succeed opening buttons could bit bigger vibration could stronger good reception shabby using elevator remarkable feat considering old phone would lose service simply putting pocket compared old samsung phone works quite well ring tones loud enough hear phone actually charges quickly great battery life heat like potatoe oven either long phone convos nice bright large screen cute ways customize scroll bar set purple pink aqua orange etc overall okay phone serves purpose definitely pales comparison new phones coming sprint get get great\n",
            "Summary: _START_ def not best but not worst  _END_\n",
            "\n",
            "\n",
            "Review: due software issue nokia sprint phone text messaging capabilities work sprint system software patch comes time next months spend least hour sprint award winning customer service team find someone admit problem nokia designed phones incoming messages retrieved quickly viewed offline way providers work sprint however likes people hook server first stay connected burning minutes check inbox compose reply wait sprint server respond send innovation money making finest\n",
            "Summary: _START_ text messaging doesn work  _END_\n",
            "\n",
            "\n",
            "Review: great reliable phone also purchased phone samsung died menu easily comprehendable speed dialing available around numbers voice dialing also nice feature takes longer speed dialing thing bothers games nokia seems taken snake phones skydiving game bowling tennis ringers nice feature available choose different ringer person calling however ringtones available online download phone pretty much stuck vibrating ringtones regular polyphonic tones need covers reasonable price range\n",
            "Summary: _START_ love this phone  _END_\n",
            "\n",
            "\n",
            "Review: love phone really need one expect price bill received one also phone little two months still yet receive free accessories supposed come phone every time call company keep telling wait couple weeks receiving shortly love phone able talking making phone calls\n",
            "Summary: _START_ love the phone but  _END_\n",
            "\n",
            "\n",
            "Review: phone great every purpose offers except day bought couldnt get case take case put pictures jaket super cool took back store employee said meant hard get well could barely even get came close snapping casing half never able get isnt big deal got dirty clear casing looks really dirty make sure get case charge time\n",
            "Summary: _START_ great phone service and options lousy case  _END_\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    print(\"Review:\",data['cleaned_text'][i])\n",
        "    print(\"Summary:\",data['cleaned_summary'][i])\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understanding the distribution of the sequences"
      ],
      "metadata": {
        "id": "IVisd7kJhyxj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "X-kYBva4rHjV",
        "outputId": "b8203d1e-d97b-47c7-c443-5f2b44f2f483"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in data['cleaned_text']:\n",
        "      text_word_count.append(len(i.split()))\n",
        "\n",
        "for i in data['cleaned_summary']:\n",
        "      summary_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "length_df.hist(bins = 20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38HDFThOrVs9",
        "outputId": "1c109492-531a-4d40-971f-a527c50d56e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9573473480395547\n",
            "0.9750777954498305\n"
          ]
        }
      ],
      "source": [
        "cnt=0\n",
        "for i in data['cleaned_text']:\n",
        "    if(len(i.split())<=100):\n",
        "        cnt=cnt+1\n",
        "cntt=0\n",
        "\n",
        "for i in data['cleaned_summary']:\n",
        "    if(len(i.split())<=15):\n",
        "      cntt=cntt+1\n",
        "\n",
        "print(cnt/len(data['cleaned_text']))\n",
        "print(cntt/len(data['cleaned_summary']))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizing the Text"
      ],
      "metadata": {
        "id": "pZ9HkPBUiJCV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xPYcUk8rK9g"
      },
      "outputs": [],
      "source": [
        "max_len_text=100 \n",
        "max_len_summary=15\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(data['cleaned_text'],data['cleaned_summary'],test_size=0.1,random_state=0,shuffle=True) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qnKBQLQrNVP"
      },
      "outputs": [],
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer()\n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr,  maxlen=max_len_text, padding='post') \n",
        "x_val   =   pad_sequences(x_val, maxlen=max_len_text, padding='post')\n",
        "\n",
        "x_voc_size   =  len(x_tokenizer.word_index) +1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QH4c51_Irkd6"
      },
      "outputs": [],
      "source": [
        "#preparing a tokenizer for summary on training data \n",
        "y_tokenizer = Tokenizer()\n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "#convert summary sequences into integer sequences\n",
        "y_tr    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr, maxlen=max_len_summary, padding='post')\n",
        "y_val   =   pad_sequences(y_val, maxlen=max_len_summary, padding='post')\n",
        "\n",
        "y_voc_size  =   len(y_tokenizer.word_index) +1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from AttentionLayer import  AttentionLayer"
      ],
      "metadata": {
        "id": "QTniOH6qi4Dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P22wJli_rngQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model building"
      ],
      "metadata": {
        "id": "eWJQM69niNej"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPa93T4Tro_0",
        "outputId": "384196f5-b182-4ff1-fc63-058d30fa3e38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 100, 300)     9207300     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 100, 300), ( 721200      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 100, 300), ( 721200      lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    2788800     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 100, 300), ( 721200      lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 300),  721200      embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 600)    0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 9296)   5586896     concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 20,648,096\n",
            "Trainable params: 20,648,096\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras import backend as K \n",
        "K.clear_session() \n",
        "latent_dim = 300 \n",
        "\n",
        "# Encoder \n",
        "encoder_inputs = Input(shape=(max_len_text,)) \n",
        "enc_emb = Embedding(x_voc_size, latent_dim,trainable=True)(encoder_inputs) \n",
        "\n",
        "#LSTM 1 \n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
        "\n",
        "#LSTM 2 \n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
        "\n",
        "#LSTM 3 \n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
        "\n",
        "# Set up the decoder. \n",
        "decoder_inputs = Input(shape=(None,)) \n",
        "dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True) \n",
        "dec_emb = dec_emb_layer(decoder_inputs) \n",
        "\n",
        "#LSTM using encoder_states as initial state\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
        "\n",
        "#Attention Layer\n",
        "attn_layer = AttentionLayer(name='attention_layer') \n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
        "\n",
        "# Concat attention output and decoder LSTM output \n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) \n",
        "decoder_outputs = decoder_dense(decoder_concat_input) \n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMPgvsmIrqfH"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUE_qnWq3IYr"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = \"/content/drive/MyDrive/projet DL/cp.ckpt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioAbp4h73Go6"
      },
      "outputs": [],
      "source": [
        "# Create a callback that saves the model's weights every 5 epochs\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    save_freq=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWHdjiccrw4o"
      },
      "outputs": [],
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmQVQB0nrxE_",
        "outputId": "d68fbe82-68c7-4ffe-b6cc-adb951a49988"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 77],\n",
              "        [109],\n",
              "        [ 15],\n",
              "        ...,\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  3],\n",
              "        [ 12],\n",
              "        [950],\n",
              "        ...,\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[ 40],\n",
              "        [  3],\n",
              "        [  1],\n",
              "        ...,\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 18],\n",
              "        [ 35],\n",
              "        [  1],\n",
              "        ...,\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[ 10],\n",
              "        [  6],\n",
              "        [  1],\n",
              "        ...,\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[ 61],\n",
              "        [  3],\n",
              "        [  1],\n",
              "        ...,\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "x_tr\n",
        "y_tr[:,:-1]\n",
        "y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkcCPhoTbXqe",
        "outputId": "1246eb36-b5cc-4097-c776-e747034bc993"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f86df949190>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# model.load_weights(checkpoint_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_GqBuWAcVMB"
      },
      "outputs": [],
      "source": [
        "#get the latest checkpoint file\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "latest = tf.train.latest_checkpoint(checkpoint_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zpFBoeeehgt",
        "outputId": "8c035d7c-22c0-4621-e642-a8f99922ae2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f86df1569d0>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "model.load_weights(latest)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxP9p3Z6ry58",
        "outputId": "8ee9af16-95de-4c78-9d02-e05dbb04918d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 65074 samples, validate on 7231 samples\n",
            "\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "  500/65074 [..............................] - ETA: 1:18:05 - loss: 1.4808\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            " 1000/65074 [..............................] - ETA: 1:13:15 - loss: 1.4788\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            " 1500/65074 [..............................] - ETA: 1:10:47 - loss: 1.4973\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            " 2000/65074 [..............................] - ETA: 1:09:35 - loss: 1.4845\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            " 2500/65074 [>.............................] - ETA: 1:07:51 - loss: 1.4725\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            " 3000/65074 [>.............................] - ETA: 1:07:11 - loss: 1.4775\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            " 3500/65074 [>.............................] - ETA: 1:06:09 - loss: 1.4741\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            " 4000/65074 [>.............................] - ETA: 1:05:08 - loss: 1.4786\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            " 4500/65074 [=>............................] - ETA: 1:04:03 - loss: 1.4770\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            " 5000/65074 [=>............................] - ETA: 1:03:08 - loss: 1.4815\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            " 5500/65074 [=>............................] - ETA: 1:02:15 - loss: 1.4788\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            " 6000/65074 [=>............................] - ETA: 1:01:27 - loss: 1.4859\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            " 6500/65074 [=>............................] - ETA: 1:00:45 - loss: 1.4789\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            " 7000/65074 [==>...........................] - ETA: 1:00:01 - loss: 1.4777\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            " 7500/65074 [==>...........................] - ETA: 59:22 - loss: 1.4744  \n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            " 8000/65074 [==>...........................] - ETA: 58:42 - loss: 1.4741\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            " 8500/65074 [==>...........................] - ETA: 58:05 - loss: 1.4742\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            " 9000/65074 [===>..........................] - ETA: 57:27 - loss: 1.4760\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            " 9500/65074 [===>..........................] - ETA: 56:53 - loss: 1.4793\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "10000/65074 [===>..........................] - ETA: 56:16 - loss: 1.4837\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "10500/65074 [===>..........................] - ETA: 55:41 - loss: 1.4815\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "11000/65074 [====>.........................] - ETA: 55:08 - loss: 1.4817\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "11500/65074 [====>.........................] - ETA: 54:32 - loss: 1.4806\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "12000/65074 [====>.........................] - ETA: 53:59 - loss: 1.4770\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "12500/65074 [====>.........................] - ETA: 53:25 - loss: 1.4775\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "13000/65074 [====>.........................] - ETA: 52:51 - loss: 1.4773\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "13500/65074 [=====>........................] - ETA: 52:19 - loss: 1.4753\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "14000/65074 [=====>........................] - ETA: 51:46 - loss: 1.4750\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "14500/65074 [=====>........................] - ETA: 51:14 - loss: 1.4745\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "15000/65074 [=====>........................] - ETA: 50:41 - loss: 1.4740\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "15500/65074 [======>.......................] - ETA: 50:10 - loss: 1.4719\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "16000/65074 [======>.......................] - ETA: 49:37 - loss: 1.4742\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "16500/65074 [======>.......................] - ETA: 49:04 - loss: 1.4718\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "17000/65074 [======>.......................] - ETA: 48:33 - loss: 1.4699\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "17500/65074 [=======>......................] - ETA: 48:01 - loss: 1.4673\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "18000/65074 [=======>......................] - ETA: 47:30 - loss: 1.4702\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "18500/65074 [=======>......................] - ETA: 46:58 - loss: 1.4680\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "19000/65074 [=======>......................] - ETA: 46:26 - loss: 1.4701\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "19500/65074 [=======>......................] - ETA: 45:56 - loss: 1.4703\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "20000/65074 [========>.....................] - ETA: 45:24 - loss: 1.4695\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "20500/65074 [========>.....................] - ETA: 44:53 - loss: 1.4689\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "21000/65074 [========>.....................] - ETA: 44:22 - loss: 1.4692\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "21500/65074 [========>.....................] - ETA: 43:50 - loss: 1.4701\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "22000/65074 [=========>....................] - ETA: 43:18 - loss: 1.4698\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "22500/65074 [=========>....................] - ETA: 42:47 - loss: 1.4684\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "23000/65074 [=========>....................] - ETA: 42:16 - loss: 1.4703\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "23500/65074 [=========>....................] - ETA: 41:45 - loss: 1.4708\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "24000/65074 [==========>...................] - ETA: 41:14 - loss: 1.4721\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "24500/65074 [==========>...................] - ETA: 40:43 - loss: 1.4719\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "25000/65074 [==========>...................] - ETA: 40:12 - loss: 1.4730\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "25500/65074 [==========>...................] - ETA: 39:42 - loss: 1.4706\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "26000/65074 [==========>...................] - ETA: 39:11 - loss: 1.4713\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "26500/65074 [===========>..................] - ETA: 38:41 - loss: 1.4707\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "27000/65074 [===========>..................] - ETA: 38:10 - loss: 1.4712\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "27500/65074 [===========>..................] - ETA: 37:39 - loss: 1.4722\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "28000/65074 [===========>..................] - ETA: 37:09 - loss: 1.4714\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "28500/65074 [============>.................] - ETA: 36:38 - loss: 1.4690\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "29000/65074 [============>.................] - ETA: 36:08 - loss: 1.4683\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "29500/65074 [============>.................] - ETA: 35:37 - loss: 1.4686\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "30000/65074 [============>.................] - ETA: 35:07 - loss: 1.4694\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "30500/65074 [=============>................] - ETA: 34:36 - loss: 1.4699\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "31000/65074 [=============>................] - ETA: 34:06 - loss: 1.4716\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "31500/65074 [=============>................] - ETA: 33:35 - loss: 1.4733\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "32000/65074 [=============>................] - ETA: 33:04 - loss: 1.4720\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "32500/65074 [=============>................] - ETA: 32:34 - loss: 1.4702\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "33000/65074 [==============>...............] - ETA: 32:04 - loss: 1.4690\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "33500/65074 [==============>...............] - ETA: 31:34 - loss: 1.4672\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "34000/65074 [==============>...............] - ETA: 31:03 - loss: 1.4661\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "34500/65074 [==============>...............] - ETA: 30:33 - loss: 1.4650\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "35000/65074 [===============>..............] - ETA: 30:03 - loss: 1.4650\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "35500/65074 [===============>..............] - ETA: 29:32 - loss: 1.4659\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "36000/65074 [===============>..............] - ETA: 29:02 - loss: 1.4662\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "36500/65074 [===============>..............] - ETA: 28:32 - loss: 1.4670\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "37000/65074 [================>.............] - ETA: 28:03 - loss: 1.4676\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "37500/65074 [================>.............] - ETA: 27:33 - loss: 1.4680\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "38000/65074 [================>.............] - ETA: 27:04 - loss: 1.4681\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "38500/65074 [================>.............] - ETA: 26:35 - loss: 1.4678\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "39000/65074 [================>.............] - ETA: 26:06 - loss: 1.4689\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "39500/65074 [=================>............] - ETA: 25:36 - loss: 1.4680\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "40000/65074 [=================>............] - ETA: 25:07 - loss: 1.4684\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "40500/65074 [=================>............] - ETA: 24:38 - loss: 1.4679\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "41000/65074 [=================>............] - ETA: 24:08 - loss: 1.4673\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "41500/65074 [==================>...........] - ETA: 23:38 - loss: 1.4685\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "42000/65074 [==================>...........] - ETA: 23:08 - loss: 1.4684\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "42500/65074 [==================>...........] - ETA: 22:38 - loss: 1.4676\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "43000/65074 [==================>...........] - ETA: 22:07 - loss: 1.4660\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "43500/65074 [===================>..........] - ETA: 21:37 - loss: 1.4658\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "44000/65074 [===================>..........] - ETA: 21:07 - loss: 1.4662\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "44500/65074 [===================>..........] - ETA: 20:36 - loss: 1.4650\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "45000/65074 [===================>..........] - ETA: 20:06 - loss: 1.4649\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "45500/65074 [===================>..........] - ETA: 19:36 - loss: 1.4648\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "46000/65074 [====================>.........] - ETA: 19:06 - loss: 1.4647\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "46500/65074 [====================>.........] - ETA: 18:35 - loss: 1.4636\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "47000/65074 [====================>.........] - ETA: 18:05 - loss: 1.4639\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "47500/65074 [====================>.........] - ETA: 17:35 - loss: 1.4640\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "48000/65074 [=====================>........] - ETA: 17:05 - loss: 1.4632\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "48500/65074 [=====================>........] - ETA: 16:35 - loss: 1.4634\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "49000/65074 [=====================>........] - ETA: 16:04 - loss: 1.4638\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "49500/65074 [=====================>........] - ETA: 15:34 - loss: 1.4641\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "50000/65074 [======================>.......] - ETA: 15:04 - loss: 1.4642\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "50500/65074 [======================>.......] - ETA: 14:34 - loss: 1.4650\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "51000/65074 [======================>.......] - ETA: 14:04 - loss: 1.4660\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "51500/65074 [======================>.......] - ETA: 13:34 - loss: 1.4655\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "52000/65074 [======================>.......] - ETA: 13:04 - loss: 1.4656\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "52500/65074 [=======================>......] - ETA: 12:34 - loss: 1.4655\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "53000/65074 [=======================>......] - ETA: 12:04 - loss: 1.4664\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "53500/65074 [=======================>......] - ETA: 11:34 - loss: 1.4667\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "54000/65074 [=======================>......] - ETA: 11:04 - loss: 1.4670\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "54500/65074 [========================>.....] - ETA: 10:34 - loss: 1.4667\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "55000/65074 [========================>.....] - ETA: 10:03 - loss: 1.4667\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "55500/65074 [========================>.....] - ETA: 9:33 - loss: 1.4663 \n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "56000/65074 [========================>.....] - ETA: 9:03 - loss: 1.4669\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "56500/65074 [=========================>....] - ETA: 8:33 - loss: 1.4676\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "57000/65074 [=========================>....] - ETA: 8:03 - loss: 1.4675\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "57500/65074 [=========================>....] - ETA: 7:33 - loss: 1.4675\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "58000/65074 [=========================>....] - ETA: 7:03 - loss: 1.4668\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "58500/65074 [=========================>....] - ETA: 6:33 - loss: 1.4670\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "59000/65074 [==========================>...] - ETA: 6:03 - loss: 1.4669\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "59500/65074 [==========================>...] - ETA: 5:33 - loss: 1.4668\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "60000/65074 [==========================>...] - ETA: 5:03 - loss: 1.4660\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "60500/65074 [==========================>...] - ETA: 4:33 - loss: 1.4666\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "61000/65074 [===========================>..] - ETA: 4:03 - loss: 1.4670\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "61500/65074 [===========================>..] - ETA: 3:33 - loss: 1.4672\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "62000/65074 [===========================>..] - ETA: 3:04 - loss: 1.4674\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "62500/65074 [===========================>..] - ETA: 2:34 - loss: 1.4674\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "63000/65074 [============================>.] - ETA: 2:04 - loss: 1.4676\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "63500/65074 [============================>.] - ETA: 1:34 - loss: 1.4681\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "64000/65074 [============================>.] - ETA: 1:04 - loss: 1.4680\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "64500/65074 [============================>.] - ETA: 34s - loss: 1.4684 \n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "65000/65074 [============================>.] - ETA: 4s - loss: 1.4682 \n",
            "Epoch 00001: saving model to /content/drive/MyDrive/projet DL/cp.ckpt\n",
            "65074/65074 [==============================] - 4026s 62ms/sample - loss: 1.4682 - val_loss: 1.4807\n"
          ]
        }
      ],
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=1,callbacks=[cp_callback],batch_size=500, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbvg9Wj3r4FK"
      },
      "outputs": [],
      "source": [
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense\n",
        "# from keras.utils import plot_model\n",
        "# from tensorflow import keras\n",
        "\n",
        "# keras.utils.plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcNO8jS0s38Q"
      },
      "outputs": [],
      "source": [
        "\n",
        "reverse_target_word_index=y_tokenizer.index_word \n",
        "reverse_source_word_index=x_tokenizer.index_word \n",
        "target_word_index=y_tokenizer.word_index"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Predictions"
      ],
      "metadata": {
        "id": "PhnSo8Zuivag"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euu-w88Bs6A_"
      },
      "outputs": [],
      "source": [
        "# encoder inference\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# decoder inference\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_len_text,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs2] + [state_h2, state_c2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYPgySFCs7mH"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    #print('input_seq: {}, e_out: {} '.format(input_seq,e_out))\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "\n",
        "    # Chose the 'start' word as the first word of the target sequence\n",
        "    target_seq[0, 0] = target_word_index['start']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "       # print(\"sampled_token:\",sampled_token)\n",
        "        if(sampled_token!='end'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "            # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_len_summary-1)):\n",
        "                stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        # stop_condition = True\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qw1844AKs9Na"
      },
      "outputs": [],
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
        "        newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if(i!=0):\n",
        "        newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3f-LQWbs-yP",
        "outputId": "4c98cbec-f23f-42ab-a10a-5573f5391b60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: yes samsung phones twice like battery life sucks using phone less two years needed charge several times day horrible get slow time none problem pro good quality product happy buying one wife suck samsung \n",
            "Original summary: going back to samsung never again \n",
            "Predicted summary:  great phone\n",
            "\n",
            "\n",
            "Review: nice get \n",
            "Original summary: everything \n",
            "Predicted summary:  good phone\n",
            "\n",
            "\n",
            "Review: really love phone smart phone first kinds touch screen smart phones coming straight garbage phone know looking get bells whistles great phone windows platform bad advertised really enjoy platform actually easy use simple learn phone lightning quick biggest pet peeve though functional pad qwerty touch screen pad get annoying overall really minor issue think phone great would trade enjoy heck simple guy fancy phone need \n",
            "Original summary: solid phone \n",
            "Predicted summary:  great phone\n",
            "\n",
            "\n",
            "Review: live phone far great upgrade samsung galaxy works perfectly usa straight talk \n",
            "Original summary: works perfectly in the usa on straight talk love it \n",
            "Predicted summary:  great phone\n",
            "\n",
            "\n",
            "Review: good phone overall biggest complains limitations small internal memory sony camera placement fingers phone edge please pull little front camera camera stabilization insane phone oddly rear camera \n",
            "Original summary: well does phone things if you like big screens and great selfies buy it \n",
            "Predicted summary:  great phone for the price\n",
            "\n",
            "\n",
            "Review: todo perfecto solo que bateria dice que tiene capacidad esta atras \n",
            "Original summary: funciona esta liberado \n",
            "Predicted summary:  muy buen producto\n",
            "\n",
            "\n",
            "Review: purchased phone deal day get sim card traveling work time store get sim weeks phone call volume right box told store defective spoke amazon zero help told contact samsung ever buy something expensive amazon receive assistance exception problem contact samsung \n",
            "Original summary: defective right out of the box and amazon will not with the return \n",
            "Predicted summary:  not what expected\n",
            "\n",
            "\n",
            "Review: disappointed phone get months use good buy \n",
            "Original summary: dont get this product \n",
            "Predicted summary:  the phone is not good\n",
            "\n",
            "\n",
            "Review: would great actually posting review \n",
            "Original summary: five stars \n",
            "Predicted summary:  great phone\n",
            "\n",
            "\n",
            "Review: got infamous pink line death replaced warranty replacement issue second defective phone replaced seller \n",
            "Original summary: got the pink line of death replaced \n",
            "Predicted summary:  one star\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "  print(\"Review:\",seq2text(x_val[i]))\n",
        "  print(\"Original summary:\",seq2summary(y_val[i]))\n",
        "  print(\"Predicted summary:\",decode_sequence(x_val[i].reshape(1,max_len_text)))\n",
        "  print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DuUPgE5Mgb_W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DeeoLearningModelLSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}